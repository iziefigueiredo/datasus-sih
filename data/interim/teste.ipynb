{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed83582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"sih_rs_tratado.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2d0a613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analisando o arquivo: sih_rs_tratado.parquet\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17885/3903583166.py:28: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  .agg(pl.count().alias(\"contagem\")) # Conta as ocorrências e renomeia para 'contagem'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem dos 10 valores mais frequentes para a coluna 'ETNIA':\n",
      "shape: (10, 2)\n",
      "┌────────────┬──────────┐\n",
      "│ DIAG_SECUN ┆ contagem │\n",
      "│ ---        ┆ ---      │\n",
      "│ str        ┆ u32      │\n",
      "╞════════════╪══════════╡\n",
      "│ 0          ┆ 11312728 │\n",
      "│ W199       ┆ 101436   │\n",
      "│ Z370       ┆ 24124    │\n",
      "│ X588       ┆ 19745    │\n",
      "│ O800       ┆ 17858    │\n",
      "│ W999       ┆ 16744    │\n",
      "│ Y349       ┆ 15646    │\n",
      "│ W029       ┆ 12965    │\n",
      "│ V499       ┆ 7809     │\n",
      "│ J180       ┆ 7695     │\n",
      "└────────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Configuração ---\n",
    "# Ajuste o caminho se necessário\n",
    "PROCESSED_FILE_PATH = Path(\"sih_rs_tratado.parquet\")\n",
    "\n",
    "def analisar_frequencia_etnia(caminho_arquivo: Path):\n",
    "    \"\"\"\n",
    "    Lê um arquivo Parquet e conta a frequência dos 10 valores mais comuns\n",
    "    na coluna 'ETNIA'.\n",
    "    \"\"\"\n",
    "    if not caminho_arquivo.exists():\n",
    "        print(f\"ERRO: Arquivo não encontrado em '{caminho_arquivo}'\")\n",
    "        return\n",
    "\n",
    "    print(f\"Analisando o arquivo: {caminho_arquivo.name}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    try:\n",
    "        # 1. Lê o arquivo, selecionando apenas a coluna 'ETNIA' para economizar memória\n",
    "        df = pl.read_parquet(caminho_arquivo, columns=[\"DIAG_SECUN\"])\n",
    "\n",
    "        # 2. Conta a frequência de cada valor na coluna, ordena do mais frequente\n",
    "        #    para o menos, e pega os 10 primeiros.\n",
    "        contagem_etnia = (\n",
    "            df.group_by(\"DIAG_SECUN\")\n",
    "            .agg(pl.count().alias(\"contagem\")) # Conta as ocorrências e renomeia para 'contagem'\n",
    "            .sort(\"contagem\", descending=True) # Ordena pela contagem\n",
    "            .limit(10)                         # Pega os 10 primeiros\n",
    "        )\n",
    "\n",
    "        print(\"Contagem dos 10 valores mais frequentes para a coluna 'ETNIA':\")\n",
    "        print(contagem_etnia)\n",
    "\n",
    "    except pl.ColumnNotFoundError:\n",
    "        print(\"ERRO: A coluna 'ETNIA' não foi encontrada no arquivo.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro inesperado: {e}\")\n",
    "\n",
    "# --- Execução ---\n",
    "if __name__ == \"__main__\":\n",
    "    analisar_frequencia_etnia(PROCESSED_FILE_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87d7488c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns found in the file:\n",
      "['N_AIH', 'ESPEC', 'IDENT', 'CEP', 'MUNIC_RES', 'NASC', 'SEXO', 'DT_INTER', 'DT_SAIDA', 'UTI_MES_TO', 'MARCA_UTI', 'UTI_INT_TO', 'DIAR_ACOM', 'QT_DIARIAS', 'PROC_REA', 'VAL_SH', 'VAL_SP', 'VAL_TOT', 'VAL_UTI', 'NATUREZA', 'CNES', 'NAT_JUR', 'GESTAO', 'IND_VDRL', 'IDADE', 'DIAG_PRINC', 'DIAG_SECUN', 'COBRANCA', 'MORTE', 'MUNIC_MOV', 'DIAS_PERM', 'NACIONAL', 'NUM_FILHOS', 'INSTRU', 'CID_NOTIF', 'CONTRACEP1', 'CONTRACEP2', 'GESTRICO', 'INSC_PN', 'CBOR', 'CNAER', 'VINCPREV', 'INFEHOSP', 'CID_ASSO', 'CID_MORTE', 'COMPLEX', 'RACA_COR', 'ETNIA', 'DIAGSEC1', 'DIAGSEC2', 'DIAGSEC3', 'DIAGSEC4', 'DIAGSEC5', 'DIAGSEC6', 'DIAGSEC7', 'DIAGSEC8', 'DIAGSEC9', 'CGC_HOSP']\n",
      "\n",
      "Error: The required columns 'DIAS_CALCULADOS' or 'DIAS_PERM' were not found in the file. Please check your preprocess script.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the file path. Assumes the notebook is in the 'interim' folder.\n",
    "file_path = Path(\"sih_rs_tratado.parquet\")\n",
    "\n",
    "if not file_path.exists():\n",
    "    print(f\"Error: The file '{file_path}' was not found. Make sure the pipeline's step 3 has been run and the notebook is in the correct folder.\")\n",
    "else:\n",
    "    try:\n",
    "        # Read the entire Parquet file into a pandas DataFrame.\n",
    "        # This will show all columns that exist in the file.\n",
    "        df = pd.read_parquet(file_path)\n",
    "\n",
    "        # Show all existing columns to confirm if DIAS_CALCULADOS was created.\n",
    "        print(\"All columns found in the file:\")\n",
    "        print(df.columns.tolist())\n",
    "\n",
    "        # Now, try to select the relevant columns.\n",
    "        if \"DIAS_CALCULADOS\" in df.columns and \"DIAS_PERM\" in df.columns:\n",
    "            df_selected = df[[\"N_AIH\", \"DT_INTER\", \"DT_SAIDA\", \"DIAS_PERM\", \"DIAS_CALCULADOS\"]]\n",
    "            \n",
    "            print(\"\\nComparing DIAS_PERM and DIAS_CALCULADOS:\")\n",
    "            # Show a sample of records where the values are different.\n",
    "            df_diff = df_selected[df_selected[\"DIAS_PERM\"] != df_selected[\"DIAS_CALCULADOS\"]].head(20)\n",
    "            print(df_diff)\n",
    "\n",
    "            # Print a summary of the differences.\n",
    "            total_diff = len(df_selected[df_selected[\"DIAS_PERM\"] != df_selected[\"DIAS_CALCULADOS\"]])\n",
    "            total_records = len(df_selected)\n",
    "            print(f\"\\nTotal records checked: {total_records:,}\")\n",
    "            print(f\"Total records with a difference: {total_diff:,}\")\n",
    "        else:\n",
    "            print(\"\\nError: The required columns 'DIAS_CALCULADOS' or 'DIAS_PERM' were not found in the file. Please check your preprocess script.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25155224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros onde 'DIAS_PERM' é diferente de 'DIAS_CALCULADOS':\n",
      "            N_AIH   DT_INTER   DT_SAIDA  DIAS_PERM  QT_DIARIAS  \\\n",
      "0   4311103536620 2011-06-13 2011-06-15          0           0   \n",
      "1   4319101186521 2019-04-01 2019-05-03          0           0   \n",
      "2   4323100525381 2023-01-23 2023-01-24          0           0   \n",
      "4   4321104078060 2021-05-14 2021-05-29          0           0   \n",
      "5   4323104602872 2023-05-14 2023-05-15          0           0   \n",
      "6   4321100421726 2021-02-06 2021-02-18          0           0   \n",
      "7   4312102764816 2012-06-11 2012-06-14          0           0   \n",
      "8   4319105336436 2019-08-08 2019-08-09          0           0   \n",
      "9   4312104679344 2012-07-06 2012-07-13          0           0   \n",
      "10  4319102001170 2019-05-08 2019-05-10          0           0   \n",
      "11  4317105627990 2017-08-18 2017-08-19          0           0   \n",
      "12  4313104009005 2013-06-12 2013-06-14          0           0   \n",
      "13  4321105147359 2021-07-19 2021-07-22          0           0   \n",
      "15  4317106611477 2017-09-13 2017-09-16          0           0   \n",
      "16  4313108518202 2013-12-17 2013-12-22          0           0   \n",
      "17  4318105919567 2018-08-20 2018-08-26          0           0   \n",
      "18  4321103066313 2021-05-13 2021-05-18          0           0   \n",
      "19  4317109215804 2017-12-01 2017-12-21          0           0   \n",
      "20  4323100979010 2023-02-04 2023-02-14          0           0   \n",
      "21  4309102463611 2009-04-18 2009-04-21          0           0   \n",
      "\n",
      "    DIAS_CALCULADOS  \n",
      "0                 2  \n",
      "1                32  \n",
      "2                 1  \n",
      "4                15  \n",
      "5                 1  \n",
      "6                12  \n",
      "7                 3  \n",
      "8                 1  \n",
      "9                 7  \n",
      "10                2  \n",
      "11                1  \n",
      "12                2  \n",
      "13                3  \n",
      "15                3  \n",
      "16                5  \n",
      "17                6  \n",
      "18                5  \n",
      "19               20  \n",
      "20               10  \n",
      "21                3  \n",
      "\n",
      "Resumo das diferenças:\n",
      "Total de registros analisados: 11,821,898\n",
      "Total de registros com diferença: 11,066,960\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Define o caminho do arquivo.\n",
    "file_path = Path(\"sih_rs_tratado.parquet\")\n",
    "\n",
    "if not file_path.exists():\n",
    "    print(f\"Erro: Arquivo '{file_path}' não encontrado. Certifique-se de que a etapa 3 do pipeline foi executada e que o notebook está na pasta correta.\")\n",
    "else:\n",
    "    try:\n",
    "        # Lê o arquivo Parquet, selecionando as colunas necessárias\n",
    "        df = pd.read_parquet(file_path, columns=[\"N_AIH\", \"DT_INTER\", \"DT_SAIDA\", \"DIAS_PERM\", \"QT_DIARIAS\"])\n",
    "\n",
    "        # Converte as colunas de data para o tipo datetime\n",
    "        df['DT_INTER'] = pd.to_datetime(df['DT_INTER'])\n",
    "        df['DT_SAIDA'] = pd.to_datetime(df['DT_SAIDA'])\n",
    "\n",
    "        # Cria a nova coluna 'DIAS_CALCULADOS'\n",
    "        df['DIAS_CALCULADOS'] = (df['DT_SAIDA'] - df['DT_INTER']).dt.days\n",
    "\n",
    "        # Exibe os registros onde há diferença entre as colunas\n",
    "        df_diff = df[df['DIAS_PERM'] != df['DIAS_CALCULADOS']]\n",
    "\n",
    "        print(\"Registros onde 'DIAS_PERM' é diferente de 'DIAS_CALCULADOS':\")\n",
    "        print(df_diff.head(20))\n",
    "\n",
    "        print(\"\\nResumo das diferenças:\")\n",
    "        total_diferentes = len(df_diff)\n",
    "        total_registros = len(df)\n",
    "        \n",
    "        print(f\"Total de registros analisados: {total_registros:,}\")\n",
    "        print(f\"Total de registros com diferença: {total_diferentes:,}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro ao ler o arquivo ou processar os dados: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
