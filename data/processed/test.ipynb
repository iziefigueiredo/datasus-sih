{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98bfeac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de9ae9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet(\"diagnosticos.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a8cb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a análise de inconsistência de códigos de município...\n",
      "Carregando 'internacoes.parquet'...\n",
      "Carregando 'municipios.parquet'...\n",
      "Executando anti-join para encontrar códigos órfãos...\n",
      "\n",
      "==================================================\n",
      "🚨 ALERTA! Encontrados 11 códigos 'MUNIC_RES' órfãos (sem correspondência).\n",
      "==================================================\n",
      "Amostra dos códigos não encontrados:\n",
      "shape: (11, 1)\n",
      "┌───────────┐\n",
      "│ MUNIC_RES │\n",
      "│ ---       │\n",
      "│ str       │\n",
      "╞═══════════╡\n",
      "│ 530100    │\n",
      "│ 530030    │\n",
      "│ 530120    │\n",
      "│ 530040    │\n",
      "│ 530150    │\n",
      "│ …         │\n",
      "│ 530140    │\n",
      "│ 530130    │\n",
      "│ 530070    │\n",
      "│ 530180    │\n",
      "│ 530050    │\n",
      "└───────────┘\n",
      "\n",
      "Contando a frequência de cada código órfão no arquivo de internações completo...\n",
      "\n",
      "Códigos órfãos mais frequentes:\n",
      "shape: (11, 2)\n",
      "┌───────────┬───────────────────────┐\n",
      "│ MUNIC_RES ┆ numero_de_ocorrencias │\n",
      "│ ---       ┆ ---                   │\n",
      "│ str       ┆ u32                   │\n",
      "╞═══════════╪═══════════════════════╡\n",
      "│ 530180    ┆ 11                    │\n",
      "│ 530040    ┆ 6                     │\n",
      "│ 530070    ┆ 5                     │\n",
      "│ 530030    ┆ 4                     │\n",
      "│ 530140    ┆ 3                     │\n",
      "│ …         ┆ …                     │\n",
      "│ 530150    ┆ 2                     │\n",
      "│ 530090    ┆ 1                     │\n",
      "│ 530120    ┆ 1                     │\n",
      "│ 530130    ┆ 1                     │\n",
      "│ 530100    ┆ 1                     │\n",
      "└───────────┴───────────────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40495/4099976251.py:70: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  .agg(pl.count().alias(\"numero_de_ocorrencias\"))\n",
      "/tmp/ipykernel_40495/4099976251.py:72: DeprecationWarning: `is_in` with a collection of the same datatype is ambiguous and deprecated.\n",
      "Please use `implode` to return to previous behavior.\n",
      "\n",
      "See https://github.com/pola-rs/polars/issues/22149 for more information.\n",
      "  .collect()\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CONFIGURAÇÃO ---\n",
    "# Defina o caminho para a pasta onde os arquivos .parquet estão localizados.\n",
    "# Assumindo que o notebook está no mesmo diretório dos arquivos.\n",
    "# Se não estiver, ajuste o caminho. Ex: DATA_DIR = Path(\"caminho/para/pasta/processed\")\n",
    "DATA_DIR = Path(\".\") \n",
    "\n",
    "# Nomes dos arquivos\n",
    "INTERNACOES_FILE = \"internacoes.parquet\"\n",
    "MUNICIPIOS_FILE = \"municipios.parquet\"\n",
    "\n",
    "# --- ANÁLISE ---\n",
    "print(\"Iniciando a análise de inconsistência de códigos de município...\")\n",
    "\n",
    "try:\n",
    "    # 1. Carregar os DataFrames de forma \"lazy\" (preguiçosa) para economizar memória\n",
    "    print(f\"Carregando '{INTERNACOES_FILE}'...\")\n",
    "    df_internacoes_lazy = pl.scan_parquet(DATA_DIR / INTERNACOES_FILE)\n",
    "\n",
    "    print(f\"Carregando '{MUNICIPIOS_FILE}'...\")\n",
    "    df_municipios_lazy = pl.scan_parquet(DATA_DIR / MUNICIPIOS_FILE)\n",
    "\n",
    "    # 2. Selecionar apenas as colunas de interesse para a análise\n",
    "    # Seleciona a coluna MUNIC_RES e garante que ela seja do tipo String\n",
    "    internacoes_codigos = df_internacoes_lazy.select(\n",
    "        pl.col(\"MUNIC_RES\").cast(pl.String)\n",
    "    ).unique()\n",
    "\n",
    "    # Seleciona a coluna codigo_6d e garante que ela seja do tipo String\n",
    "    municipios_codigos = df_municipios_lazy.select(\n",
    "        pl.col(\"codigo_6d\").cast(pl.String)\n",
    "    ).unique()\n",
    "\n",
    "    # 3. Executar o ANTI-JOIN\n",
    "    # Esta é a operação principal: ela encontra todos os MUNIC_RES em 'internacoes_codigos'\n",
    "    # que NÃO existem em 'municipios_codigos'.\n",
    "    print(\"Executando anti-join para encontrar códigos órfãos...\")\n",
    "    codigos_orfaos = internacoes_codigos.join(\n",
    "        municipios_codigos,\n",
    "        left_on=\"MUNIC_RES\",\n",
    "        right_on=\"codigo_6d\",\n",
    "        how=\"anti\"\n",
    "    )\n",
    "\n",
    "    # Coleta o resultado (traz os dados para a memória)\n",
    "    resultado_orfaos = codigos_orfaos.collect()\n",
    "\n",
    "    # 4. Apresentar os resultados\n",
    "    if resultado_orfaos.is_empty():\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"✅ SUCESSO! Todos os códigos 'MUNIC_RES' foram encontrados na tabela de municípios.\")\n",
    "        print(\"=\"*50)\n",
    "    else:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"🚨 ALERTA! Encontrados {len(resultado_orfaos)} códigos 'MUNIC_RES' órfãos (sem correspondência).\")\n",
    "        print(\"=\"*50)\n",
    "        print(\"Amostra dos códigos não encontrados:\")\n",
    "        print(resultado_orfaos.head(20)) # Mostra os primeiros 20 códigos órfãos\n",
    "\n",
    "        # Opcional: Contar a frequência de cada código órfão para ver os mais problemáticos\n",
    "        print(\"\\nContando a frequência de cada código órfão no arquivo de internações completo...\")\n",
    "        \n",
    "        # Re-lê o arquivo de internações para contar as ocorrências\n",
    "        contagem_orfaos = (\n",
    "            pl.scan_parquet(DATA_DIR / INTERNACOES_FILE)\n",
    "            .filter(pl.col(\"MUNIC_RES\").is_in(resultado_orfaos[\"MUNIC_RES\"]))\n",
    "            .group_by(\"MUNIC_RES\")\n",
    "            .agg(pl.count().alias(\"numero_de_ocorrencias\"))\n",
    "            .sort(\"numero_de_ocorrencias\", descending=True)\n",
    "            .collect()\n",
    "        )\n",
    "        \n",
    "        print(\"\\nCódigos órfãos mais frequentes:\")\n",
    "        print(contagem_orfaos.head(20))\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nERRO: Arquivo não encontrado. Verifique se os nomes e o caminho estão corretos.\")\n",
    "    print(f\"Detalhe do erro: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nOcorreu um erro inesperado durante a análise: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1f89dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando verificação de consistência interna do arquivo: 'internacoes.parquet'\n",
      "================================================================================\n",
      "Arquivo encontrado. Total de registros a serem verificados: 11,821,898\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✅ SUCESSO! O arquivo 'internacoes.parquet' está 100% consistente.\n",
      "   A coluna 'DIAS_PERM' corresponde perfeitamente ao cálculo (DT_SAIDA - DT_INTER).\n",
      "   Isso sugere que a inconsistência está sendo introduzida na etapa de AGREGAÇÃO ('aggregate.py').\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CONFIGURAÇÃO ---\n",
    "# Caminho para o arquivo que sai do pré-processamento\n",
    "PREPROCESSED_FILE = Path(\"internacoes.parquet\")\n",
    "\n",
    "print(f\"Iniciando verificação de consistência interna do arquivo: '{PREPROCESSED_FILE}'\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    # Usamos scan_parquet para ser eficiente com a memória\n",
    "    lazy_df = pl.scan_parquet(PREPROCESSED_FILE)\n",
    "    total_registros = lazy_df.select(pl.len()).collect().item()\n",
    "    print(f\"Arquivo encontrado. Total de registros a serem verificados: {total_registros:,}\")\n",
    "\n",
    "    # --- Verificação de Consistência ---\n",
    "    \n",
    "    # Filtra o DataFrame para encontrar linhas onde DIAS_PERM não bate com o cálculo das datas\n",
    "    # Usamos .dt.total_days() para extrair o número de dias da diferença\n",
    "    df_inconsistentes = lazy_df.filter(\n",
    "        pl.col(\"DIAS_PERM\") != (pl.col(\"DT_SAIDA\") - pl.col(\"DT_INTER\")).dt.total_days()\n",
    "    ).collect() # .collect() executa a consulta e materializa o resultado\n",
    "\n",
    "    total_inconsistentes = len(df_inconsistentes)\n",
    "\n",
    "    print(\"-\" * 80)\n",
    "    if total_inconsistentes == 0:\n",
    "        print(\"\\n✅ SUCESSO! O arquivo 'internacoes.parquet' está 100% consistente.\")\n",
    "        print(\"   A coluna 'DIAS_PERM' corresponde perfeitamente ao cálculo (DT_SAIDA - DT_INTER).\")\n",
    "        print(\"   Isso sugere que a inconsistência está sendo introduzida na etapa de AGREGAÇÃO ('aggregate.py').\")\n",
    "    else:\n",
    "        print(f\"\\n🚨 ALERTA! Encontrados {total_inconsistentes:,} registros inconsistentes dentro do próprio arquivo 'sih_rs_tratado.parquet'.\")\n",
    "        print(\"   Isso indica um problema na lógica de recálculo dentro do 'preprocess.py'.\")\n",
    "        \n",
    "        # Adiciona a coluna de diferença para facilitar a análise\n",
    "        df_inconsistentes = df_inconsistentes.with_columns(\n",
    "            (pl.col(\"DIAS_PERM\") - (pl.col(\"DT_SAIDA\") - pl.col(\"DT_INTER\")).dt.total_days()).alias(\"diferenca\")\n",
    "        )\n",
    "        \n",
    "        print(\"\\n--- Amostra dos dados inconsistentes encontrados ---\")\n",
    "        print(df_inconsistentes.select([\n",
    "            \"N_AIH\", \"DT_INTER\", \"DT_SAIDA\", \"DIAS_PERM\", \"diferenca\"\n",
    "        ]).head(20))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nERRO: Arquivo '{PREPROCESSED_FILE}' não encontrado. Verifique o caminho.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nOcorreu um erro inesperado: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5349a1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Aponte para o arquivo que é a FONTE da sua tabela 'internacoes'\n",
    "# Geralmente é o 'internacoes.parquet' na pasta 'processed'\n",
    "ARQUIVO_FINAL = \"internacoes.parquet\" \n",
    "\n",
    "print(f\"Verificando a consistência final do arquivo: '{ARQUIVO_FINAL}'\")\n",
    "\n",
    "df = pl.read_parquet(ARQUIVO_FINAL)\n",
    "\n",
    "# Recalcula a idade usando a mesma lógica do aggregate.py\n",
    "df_verificado = df.with_columns(\n",
    "    (\n",
    "        pl.col(\"DT_INTER\").dt.year() - pl.col(\"NASC\").dt.year() -\n",
    "        pl.when(\n",
    "            (pl.col(\"DT_INTER\").dt.month() < pl.col(\"NASC\").dt.month()) |\n",
    "            ((pl.col(\"DT_INTER\").dt.month() == pl.col(\"NASC\").dt.month()) &\n",
    "             (pl.col(\"DT_INTER\").dt.day() < pl.col(\"NASC\").dt.day()))\n",
    "        )\n",
    "        .then(1)\n",
    "        .otherwise(0)\n",
    "    )\n",
    "    .cast(pl.Int16)\n",
    "    .alias(\"idade_recalculada\")\n",
    ")\n",
    "\n",
    "# Encontra as linhas onde a IDADE no arquivo não bate com o recálculo\n",
    "inconsistencias = df_verificado.filter(\n",
    "    pl.col(\"IDADE\") != pl.col(\"idade_recalculada\")\n",
    ")\n",
    "\n",
    "if inconsistencias.is_empty():\n",
    "    print(\"\\n✅ SUCESSO! O arquivo Parquet final está 100% consistente. O problema NÃO está no pipeline Python.\")\n",
    "else:\n",
    "    print(f\"\\n🚨 FALHA! Encontradas {len(inconsistencias)} inconsistências no arquivo Parquet final. O problema está no 'aggregate.py'.\")\n",
    "    print(\"Amostra das falhas:\")\n",
    "    print(inconsistencias)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
