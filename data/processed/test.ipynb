{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98bfeac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de9ae9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet(\"diagnosticos.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a8cb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a anÃ¡lise de inconsistÃªncia de cÃ³digos de municÃ­pio...\n",
      "Carregando 'internacoes.parquet'...\n",
      "Carregando 'municipios.parquet'...\n",
      "Executando anti-join para encontrar cÃ³digos Ã³rfÃ£os...\n",
      "\n",
      "==================================================\n",
      "ğŸš¨ ALERTA! Encontrados 11 cÃ³digos 'MUNIC_RES' Ã³rfÃ£os (sem correspondÃªncia).\n",
      "==================================================\n",
      "Amostra dos cÃ³digos nÃ£o encontrados:\n",
      "shape: (11, 1)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ MUNIC_RES â”‚\n",
      "â”‚ ---       â”‚\n",
      "â”‚ str       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 530100    â”‚\n",
      "â”‚ 530030    â”‚\n",
      "â”‚ 530120    â”‚\n",
      "â”‚ 530040    â”‚\n",
      "â”‚ 530150    â”‚\n",
      "â”‚ â€¦         â”‚\n",
      "â”‚ 530140    â”‚\n",
      "â”‚ 530130    â”‚\n",
      "â”‚ 530070    â”‚\n",
      "â”‚ 530180    â”‚\n",
      "â”‚ 530050    â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "Contando a frequÃªncia de cada cÃ³digo Ã³rfÃ£o no arquivo de internaÃ§Ãµes completo...\n",
      "\n",
      "CÃ³digos Ã³rfÃ£os mais frequentes:\n",
      "shape: (11, 2)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ MUNIC_RES â”† numero_de_ocorrencias â”‚\n",
      "â”‚ ---       â”† ---                   â”‚\n",
      "â”‚ str       â”† u32                   â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 530180    â”† 11                    â”‚\n",
      "â”‚ 530040    â”† 6                     â”‚\n",
      "â”‚ 530070    â”† 5                     â”‚\n",
      "â”‚ 530030    â”† 4                     â”‚\n",
      "â”‚ 530140    â”† 3                     â”‚\n",
      "â”‚ â€¦         â”† â€¦                     â”‚\n",
      "â”‚ 530150    â”† 2                     â”‚\n",
      "â”‚ 530090    â”† 1                     â”‚\n",
      "â”‚ 530120    â”† 1                     â”‚\n",
      "â”‚ 530130    â”† 1                     â”‚\n",
      "â”‚ 530100    â”† 1                     â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40495/4099976251.py:70: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  .agg(pl.count().alias(\"numero_de_ocorrencias\"))\n",
      "/tmp/ipykernel_40495/4099976251.py:72: DeprecationWarning: `is_in` with a collection of the same datatype is ambiguous and deprecated.\n",
      "Please use `implode` to return to previous behavior.\n",
      "\n",
      "See https://github.com/pola-rs/polars/issues/22149 for more information.\n",
      "  .collect()\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CONFIGURAÃ‡ÃƒO ---\n",
    "# Defina o caminho para a pasta onde os arquivos .parquet estÃ£o localizados.\n",
    "# Assumindo que o notebook estÃ¡ no mesmo diretÃ³rio dos arquivos.\n",
    "# Se nÃ£o estiver, ajuste o caminho. Ex: DATA_DIR = Path(\"caminho/para/pasta/processed\")\n",
    "DATA_DIR = Path(\".\") \n",
    "\n",
    "# Nomes dos arquivos\n",
    "INTERNACOES_FILE = \"internacoes.parquet\"\n",
    "MUNICIPIOS_FILE = \"municipios.parquet\"\n",
    "\n",
    "# --- ANÃLISE ---\n",
    "print(\"Iniciando a anÃ¡lise de inconsistÃªncia de cÃ³digos de municÃ­pio...\")\n",
    "\n",
    "try:\n",
    "    # 1. Carregar os DataFrames de forma \"lazy\" (preguiÃ§osa) para economizar memÃ³ria\n",
    "    print(f\"Carregando '{INTERNACOES_FILE}'...\")\n",
    "    df_internacoes_lazy = pl.scan_parquet(DATA_DIR / INTERNACOES_FILE)\n",
    "\n",
    "    print(f\"Carregando '{MUNICIPIOS_FILE}'...\")\n",
    "    df_municipios_lazy = pl.scan_parquet(DATA_DIR / MUNICIPIOS_FILE)\n",
    "\n",
    "    # 2. Selecionar apenas as colunas de interesse para a anÃ¡lise\n",
    "    # Seleciona a coluna MUNIC_RES e garante que ela seja do tipo String\n",
    "    internacoes_codigos = df_internacoes_lazy.select(\n",
    "        pl.col(\"MUNIC_RES\").cast(pl.String)\n",
    "    ).unique()\n",
    "\n",
    "    # Seleciona a coluna codigo_6d e garante que ela seja do tipo String\n",
    "    municipios_codigos = df_municipios_lazy.select(\n",
    "        pl.col(\"codigo_6d\").cast(pl.String)\n",
    "    ).unique()\n",
    "\n",
    "    # 3. Executar o ANTI-JOIN\n",
    "    # Esta Ã© a operaÃ§Ã£o principal: ela encontra todos os MUNIC_RES em 'internacoes_codigos'\n",
    "    # que NÃƒO existem em 'municipios_codigos'.\n",
    "    print(\"Executando anti-join para encontrar cÃ³digos Ã³rfÃ£os...\")\n",
    "    codigos_orfaos = internacoes_codigos.join(\n",
    "        municipios_codigos,\n",
    "        left_on=\"MUNIC_RES\",\n",
    "        right_on=\"codigo_6d\",\n",
    "        how=\"anti\"\n",
    "    )\n",
    "\n",
    "    # Coleta o resultado (traz os dados para a memÃ³ria)\n",
    "    resultado_orfaos = codigos_orfaos.collect()\n",
    "\n",
    "    # 4. Apresentar os resultados\n",
    "    if resultado_orfaos.is_empty():\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"âœ… SUCESSO! Todos os cÃ³digos 'MUNIC_RES' foram encontrados na tabela de municÃ­pios.\")\n",
    "        print(\"=\"*50)\n",
    "    else:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"ğŸš¨ ALERTA! Encontrados {len(resultado_orfaos)} cÃ³digos 'MUNIC_RES' Ã³rfÃ£os (sem correspondÃªncia).\")\n",
    "        print(\"=\"*50)\n",
    "        print(\"Amostra dos cÃ³digos nÃ£o encontrados:\")\n",
    "        print(resultado_orfaos.head(20)) # Mostra os primeiros 20 cÃ³digos Ã³rfÃ£os\n",
    "\n",
    "        # Opcional: Contar a frequÃªncia de cada cÃ³digo Ã³rfÃ£o para ver os mais problemÃ¡ticos\n",
    "        print(\"\\nContando a frequÃªncia de cada cÃ³digo Ã³rfÃ£o no arquivo de internaÃ§Ãµes completo...\")\n",
    "        \n",
    "        # Re-lÃª o arquivo de internaÃ§Ãµes para contar as ocorrÃªncias\n",
    "        contagem_orfaos = (\n",
    "            pl.scan_parquet(DATA_DIR / INTERNACOES_FILE)\n",
    "            .filter(pl.col(\"MUNIC_RES\").is_in(resultado_orfaos[\"MUNIC_RES\"]))\n",
    "            .group_by(\"MUNIC_RES\")\n",
    "            .agg(pl.count().alias(\"numero_de_ocorrencias\"))\n",
    "            .sort(\"numero_de_ocorrencias\", descending=True)\n",
    "            .collect()\n",
    "        )\n",
    "        \n",
    "        print(\"\\nCÃ³digos Ã³rfÃ£os mais frequentes:\")\n",
    "        print(contagem_orfaos.head(20))\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nERRO: Arquivo nÃ£o encontrado. Verifique se os nomes e o caminho estÃ£o corretos.\")\n",
    "    print(f\"Detalhe do erro: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nOcorreu um erro inesperado durante a anÃ¡lise: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1f89dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando verificaÃ§Ã£o de consistÃªncia interna do arquivo: 'internacoes.parquet'\n",
      "================================================================================\n",
      "Arquivo encontrado. Total de registros a serem verificados: 11,821,898\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "âœ… SUCESSO! O arquivo 'internacoes.parquet' estÃ¡ 100% consistente.\n",
      "   A coluna 'DIAS_PERM' corresponde perfeitamente ao cÃ¡lculo (DT_SAIDA - DT_INTER).\n",
      "   Isso sugere que a inconsistÃªncia estÃ¡ sendo introduzida na etapa de AGREGAÃ‡ÃƒO ('aggregate.py').\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CONFIGURAÃ‡ÃƒO ---\n",
    "# Caminho para o arquivo que sai do prÃ©-processamento\n",
    "PREPROCESSED_FILE = Path(\"internacoes.parquet\")\n",
    "\n",
    "print(f\"Iniciando verificaÃ§Ã£o de consistÃªncia interna do arquivo: '{PREPROCESSED_FILE}'\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    # Usamos scan_parquet para ser eficiente com a memÃ³ria\n",
    "    lazy_df = pl.scan_parquet(PREPROCESSED_FILE)\n",
    "    total_registros = lazy_df.select(pl.len()).collect().item()\n",
    "    print(f\"Arquivo encontrado. Total de registros a serem verificados: {total_registros:,}\")\n",
    "\n",
    "    # --- VerificaÃ§Ã£o de ConsistÃªncia ---\n",
    "    \n",
    "    # Filtra o DataFrame para encontrar linhas onde DIAS_PERM nÃ£o bate com o cÃ¡lculo das datas\n",
    "    # Usamos .dt.total_days() para extrair o nÃºmero de dias da diferenÃ§a\n",
    "    df_inconsistentes = lazy_df.filter(\n",
    "        pl.col(\"DIAS_PERM\") != (pl.col(\"DT_SAIDA\") - pl.col(\"DT_INTER\")).dt.total_days()\n",
    "    ).collect() # .collect() executa a consulta e materializa o resultado\n",
    "\n",
    "    total_inconsistentes = len(df_inconsistentes)\n",
    "\n",
    "    print(\"-\" * 80)\n",
    "    if total_inconsistentes == 0:\n",
    "        print(\"\\nâœ… SUCESSO! O arquivo 'internacoes.parquet' estÃ¡ 100% consistente.\")\n",
    "        print(\"   A coluna 'DIAS_PERM' corresponde perfeitamente ao cÃ¡lculo (DT_SAIDA - DT_INTER).\")\n",
    "        print(\"   Isso sugere que a inconsistÃªncia estÃ¡ sendo introduzida na etapa de AGREGAÃ‡ÃƒO ('aggregate.py').\")\n",
    "    else:\n",
    "        print(f\"\\nğŸš¨ ALERTA! Encontrados {total_inconsistentes:,} registros inconsistentes dentro do prÃ³prio arquivo 'sih_rs_tratado.parquet'.\")\n",
    "        print(\"   Isso indica um problema na lÃ³gica de recÃ¡lculo dentro do 'preprocess.py'.\")\n",
    "        \n",
    "        # Adiciona a coluna de diferenÃ§a para facilitar a anÃ¡lise\n",
    "        df_inconsistentes = df_inconsistentes.with_columns(\n",
    "            (pl.col(\"DIAS_PERM\") - (pl.col(\"DT_SAIDA\") - pl.col(\"DT_INTER\")).dt.total_days()).alias(\"diferenca\")\n",
    "        )\n",
    "        \n",
    "        print(\"\\n--- Amostra dos dados inconsistentes encontrados ---\")\n",
    "        print(df_inconsistentes.select([\n",
    "            \"N_AIH\", \"DT_INTER\", \"DT_SAIDA\", \"DIAS_PERM\", \"diferenca\"\n",
    "        ]).head(20))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nERRO: Arquivo '{PREPROCESSED_FILE}' nÃ£o encontrado. Verifique o caminho.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nOcorreu um erro inesperado: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5349a1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Aponte para o arquivo que Ã© a FONTE da sua tabela 'internacoes'\n",
    "# Geralmente Ã© o 'internacoes.parquet' na pasta 'processed'\n",
    "ARQUIVO_FINAL = \"internacoes.parquet\" \n",
    "\n",
    "print(f\"Verificando a consistÃªncia final do arquivo: '{ARQUIVO_FINAL}'\")\n",
    "\n",
    "df = pl.read_parquet(ARQUIVO_FINAL)\n",
    "\n",
    "# Recalcula a idade usando a mesma lÃ³gica do aggregate.py\n",
    "df_verificado = df.with_columns(\n",
    "    (\n",
    "        pl.col(\"DT_INTER\").dt.year() - pl.col(\"NASC\").dt.year() -\n",
    "        pl.when(\n",
    "            (pl.col(\"DT_INTER\").dt.month() < pl.col(\"NASC\").dt.month()) |\n",
    "            ((pl.col(\"DT_INTER\").dt.month() == pl.col(\"NASC\").dt.month()) &\n",
    "             (pl.col(\"DT_INTER\").dt.day() < pl.col(\"NASC\").dt.day()))\n",
    "        )\n",
    "        .then(1)\n",
    "        .otherwise(0)\n",
    "    )\n",
    "    .cast(pl.Int16)\n",
    "    .alias(\"idade_recalculada\")\n",
    ")\n",
    "\n",
    "# Encontra as linhas onde a IDADE no arquivo nÃ£o bate com o recÃ¡lculo\n",
    "inconsistencias = df_verificado.filter(\n",
    "    pl.col(\"IDADE\") != pl.col(\"idade_recalculada\")\n",
    ")\n",
    "\n",
    "if inconsistencias.is_empty():\n",
    "    print(\"\\nâœ… SUCESSO! O arquivo Parquet final estÃ¡ 100% consistente. O problema NÃƒO estÃ¡ no pipeline Python.\")\n",
    "else:\n",
    "    print(f\"\\nğŸš¨ FALHA! Encontradas {len(inconsistencias)} inconsistÃªncias no arquivo Parquet final. O problema estÃ¡ no 'aggregate.py'.\")\n",
    "    print(\"Amostra das falhas:\")\n",
    "    print(inconsistencias)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
